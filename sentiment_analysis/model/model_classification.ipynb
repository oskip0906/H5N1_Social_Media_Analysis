{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from torch.nn import functional as F\n",
    "import torch\n",
    "import os\n",
    "import zipfile\n",
    "import shutil\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "\n",
    "# Unzip the zip files\n",
    "with zipfile.ZipFile('sentiment_analysis/model/saved_model.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('sentiment_analysis/model')\n",
    "\n",
    "with zipfile.ZipFile('sentiment_analysis/model/saved_tokenizer.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('sentiment_analysis/model')\n",
    "\n",
    "# Load the model and tokenizer\n",
    "classifier = AutoModelForSequenceClassification.from_pretrained('sentiment_analysis/model/saved_model').to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained('sentiment_analysis/model/saved_tokenizer')\n",
    "\n",
    "# Define the labels\n",
    "labels = ['Sadness', 'Joy', 'Love', 'Anger', 'Fear', 'Surprise', 'Neutral']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_comment(comment):\n",
    "\n",
    "    tokenized_comment = tokenizer(comment, return_tensors='pt', padding='max_length', truncation=True).to(device)\n",
    "\n",
    "    # Perform classification\n",
    "    with torch.no_grad():\n",
    "        outputs = classifier(**tokenized_comment)\n",
    "        logits = outputs.logits\n",
    "\n",
    "    # Get the predicted class and the maximum score\n",
    "    score = F.softmax(logits, dim=-1)\n",
    "    prediction = torch.argmax(score, dim=-1).item()\n",
    "    max_score = torch.max(score).item()\n",
    "\n",
    "    # If the maximum score low, classify as 'Neutral'\n",
    "    if max_score < 0.5:\n",
    "        prediction = 6\n",
    "\n",
    "    print(f'Prediction: {labels[prediction]} | Score: {max_score}')\n",
    "\n",
    "    return labels[prediction], max_score\n",
    "\n",
    "def classify_file(file_name):\n",
    "    input_file = f'csv_files/comments_by_state/{file_name}'\n",
    "    output_file = f'csv_files/classified_comments_by_state/{file_name}'\n",
    "    comments_df = pd.read_csv(input_file)\n",
    "\n",
    "    # Apply the classifier to each comment\n",
    "    sentiments = comments_df['Comment'].apply(lambda comment: classify_comment(comment))\n",
    "\n",
    "    # Extract sentiment and intensity from the results\n",
    "    comments_df['Sentiment'] = sentiments.apply(lambda x: x[0])\n",
    "    comments_df['Intensity'] = sentiments.apply(lambda x: x[1])\n",
    "\n",
    "    # Save the classified comments\n",
    "    comments_df.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the folder containing the files\n",
    "folder = 'csv_files/comments_by_state'\n",
    "files = os.listdir(folder)\n",
    "\n",
    "# Classify comments in each file\n",
    "for file_name in files:\n",
    "    classify_file(file_name)\n",
    "\n",
    "# Concatenate all classified data into a single CSV\n",
    "data = pd.concat([pd.read_csv(f'csv_files/classified_comments_by_state/{file}') for file in files])\n",
    "data.to_csv('csv_files/classified_comments.csv', index=False)\n",
    "\n",
    "del classifier\n",
    "del tokenizer\n",
    "gc.collect()\n",
    "\n",
    "# Delete the extracted folders\n",
    "shutil.rmtree('sentiment_analysis/model/saved_model')\n",
    "shutil.rmtree('sentiment_analysis/model/saved_tokenizer')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
