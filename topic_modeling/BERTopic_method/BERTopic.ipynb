{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oskio\\OneDrive\\Documents\\GitHub\\H5N1_Social_Media_Analysis\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from bertopic import BERTopic\n",
    "import hdbscan \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import CoherenceModel\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "os.chdir('..')\n",
    "from process_comments import preprocess_comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.8\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_coherence_score(topic_words):\n",
    "\n",
    "    # Create a dictionary\n",
    "    dictionary = Dictionary(topic_words)\n",
    "    \n",
    "    # Initialize coherence model\n",
    "    coherence_model = CoherenceModel(\n",
    "        topics=topic_words,\n",
    "        texts=topic_words, \n",
    "        dictionary=dictionary,\n",
    "        coherence='c_v'\n",
    "    )\n",
    "\n",
    "    coherence_score = coherence_model.get_coherence()\n",
    "\n",
    "    return coherence_score\n",
    "\n",
    "def calculate_jaccard_similarity(topic1, topic2):\n",
    "\n",
    "    set1, set2 = set(topic1), set(topic2)\n",
    "    intersection = set1.intersection(set2)\n",
    "    union = set1.union(set2)\n",
    "\n",
    "    if union:\n",
    "        return len(intersection) / len(union)\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def calculate_average_jaccard_similarity(topics):\n",
    "    \n",
    "    total_similarity = 0\n",
    "    num_comparisons = 0\n",
    "    \n",
    "    # Compare every pair of topics\n",
    "    for topic1, topic2 in itertools.combinations(topics, 2):\n",
    "        total_similarity += calculate_jaccard_similarity(topic1, topic2)\n",
    "        num_comparisons += 1\n",
    "\n",
    "    if num_comparisons > 0:\n",
    "        return total_similarity / num_comparisons\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def topic_modeling(comments, min_cluster_size, min_samples, max_features, ngram_range):\n",
    "\n",
    "    processed_comments = []\n",
    "    for comment in comments:\n",
    "        processed_comments.append(preprocess_comment(comment))\n",
    "\n",
    "    # HDBSCAN model for clustering \n",
    "    hdbscan_model = hdbscan.HDBSCAN(\n",
    "        min_cluster_size=min_cluster_size, \n",
    "        min_samples=min_samples, \n",
    "        cluster_selection_epsilon=0.1\n",
    "    )\n",
    "    \n",
    "    # BERTopic model with adjusted parameters\n",
    "    topic_model = BERTopic(\n",
    "        hdbscan_model=hdbscan_model, \n",
    "        embedding_model=SentenceTransformer('all-MiniLM-L6-v2', device='cuda'), \n",
    "        vectorizer_model=CountVectorizer(max_features=max_features, ngram_range=ngram_range),\n",
    "    )\n",
    "\n",
    "    # fit-transform the model\n",
    "    topics, probs = topic_model.fit_transform(processed_comments)\n",
    "    \n",
    "    topics_list = {}\n",
    "    topic_words = []\n",
    "    top_comments = {}\n",
    "\n",
    "    i = 0\n",
    "    while True:\n",
    "\n",
    "        topic = topic_model.get_topic(i)\n",
    "\n",
    "        if not topic:\n",
    "            break\n",
    "        subtopics_list = [word for word, _ in topic if word != '']\n",
    "\n",
    "        if len(subtopics_list) == 0:\n",
    "            break\n",
    "        topics_list[f\"Topic {i + 1}\"] = subtopics_list\n",
    "        topic_words.append(subtopics_list)\n",
    "        \n",
    "        # Find top comments for each topic based on probabilities\n",
    "        topic_indices = [index for index, t in enumerate(topics) if t == i]\n",
    "        topic_probs = [probs[index] for index in topic_indices]\n",
    "        top_indices = sorted(range(len(topic_probs)), key=lambda k: topic_probs[k], reverse=True)[:25]\n",
    "        top_comments[f\"Topic {i + 1}\"] = [comments[topic_indices[index]] for index in top_indices]\n",
    "    \n",
    "        i += 1\n",
    "\n",
    "    if len(topics_list) == 0:\n",
    "        return None, None, topics_list, top_comments\n",
    "\n",
    "    return calculate_coherence_score(topic_words), calculate_average_jaccard_similarity(topic_words), topics_list, top_comments\n",
    "\n",
    "def find_best_topics(comments):\n",
    "\n",
    "    param_grid = {\n",
    "        'min_cluster_size': [2, 5],\n",
    "        'min_samples': [2, 5],\n",
    "        'max_features': [200, 500, 1000],\n",
    "        'ngram_range': [(1, 3), (2, 4), (3, 5)]\n",
    "    }\n",
    "\n",
    "    best_score = -1\n",
    "    best_coherence = 0\n",
    "    best_jaccard = 0\n",
    "\n",
    "    for params in ParameterGrid(param_grid):\n",
    "        coherence, jaccard, topics_list, top_comments = topic_modeling(\n",
    "            comments, \n",
    "            min_cluster_size=params['min_cluster_size'], \n",
    "            min_samples=params['min_samples'], \n",
    "            max_features=params['max_features'], \n",
    "            ngram_range=params['ngram_range']\n",
    "        )\n",
    "        if coherence and jaccard:\n",
    "            score = coherence - jaccard\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_coherence = coherence\n",
    "                best_jaccard = jaccard\n",
    "                best_topics = topics_list\n",
    "                best_comments = top_comments\n",
    "                best_params = params\n",
    "\n",
    "    return best_coherence, best_jaccard, best_params, best_topics, best_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..')\n",
    "\n",
    "# Comments by state\n",
    "folder = 'csv_files/classified_comments_by_state'\n",
    "files = os.listdir(folder)\n",
    "\n",
    "coherence_jaccard = []\n",
    "\n",
    "# Iterate through the files and find the best topics for each state \n",
    "for file in files:\n",
    "\n",
    "    if file == 'excluded_states.csv':\n",
    "        continue\n",
    "\n",
    "    state = file[:-4]\n",
    "    state_data = pd.read_csv(f'{folder}/{file}') \n",
    "    state_comment = state_data['Comment'].tolist()\n",
    "\n",
    "    best_coherence, best_jaccard, best_params, best_topics, best_comments = find_best_topics(state_comment)\n",
    "    coherence_jaccard.append(f'{state}: Coherence - {best_coherence}, Jaccard - {best_jaccard}, Params - {best_params}')\n",
    "\n",
    "    # Write the results to a file\n",
    "    with open(f'topic_modeling/BERTopic_method/topics_by_state/{state}.json', 'w') as f:\n",
    "        json.dump(best_topics, f)\n",
    "\n",
    "    # Write the top comments for each topic to a file\n",
    "    with open(f'topic_modeling/BERTopic_method/comments_by_state/{state}.json', 'w') as f:\n",
    "        json.dump(best_comments, f)\n",
    "\n",
    "# Save the coherence and jaccard scores to file\n",
    "with open(f'topic_modeling/BERTopic_method/detailed_metrics.txt', 'w') as f:\n",
    "    f.write('\\n'.join(coherence_jaccard))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
